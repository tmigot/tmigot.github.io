---
title: 'Talk on JuliaSmoothOptimizers and the NLPModel API'
date: 2022-02-15
permalink: /posts/2022/02/talk/
tags:
  - programming
  - Julia
  - PDE
  - optimization
  - talk
---
Yesterday was .... the [10th anniversary of Julia](https://julialang.org/blog/2022/02/10years/), and, yes, valentine's day also. To celebrate this, we had the opportunity to present JuliaSmoothOptimizers at the [JuMP-dev](https://jump.dev) seminar and talk about the API for nonlinear models [JuMP nonlinear developers call: The JuliaSmoothOptimizers ecosystem](https://jump.dev/developers-call/2022/02/15/jso/).

It was a great experience showing several of the features of the organization. The API defined in [`NLPModels.jl`](https://github.com/JuliaSmoothOptimizers/NLPModels.jl) has two main advantages:
- It defines a very abstract API with everything you need from a continuous optimization model (operator derivatives, sparse derivatives, in-place functions).
- It is also compatible with all the types available in Julia. For instance, in [`OptimizationProblems.jl`](https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl), you can access test problems defined with automatic differentiation on any type just by changing a keyword.
Alexis Montoison, Ph.D. student at GERAD/Polytechnique Montreal, showed during the presentation how this API can also be used on GPUs.

Everything related to the presentation is available [here](https://jump.dev/developers-call/2022/02/15/jso/) and you can watch the [youtube video](https://www.youtube.com/watch?v=FsQJ6NEUF6g&t=1s) on `The Julia Programming Language` channel.
